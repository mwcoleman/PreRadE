GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
Start to load Faster-RCNN detected objects from /media/matt/data21/mmRad/img_features/mscoco-train_2017-custom.tsv
Loaded 5000 images in file /media/matt/data21/mmRad/img_features/mscoco-train_2017-custom.tsv in 8 seconds.
Start to load Faster-RCNN detected objects from /media/matt/data21/mmRad/img_features/mscoco-val_2017-custom.tsv
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded 5000 images in file /media/matt/data21/mmRad/img_features/mscoco-val_2017-custom.tsv in 8 seconds.
Validation sanity check:   0%|                                                                                                                                                                                            | 0/2 [00:00<?, ?it/s]
Training: -1it [00:00, ?it/s]
Epoch 0:   5%|██████▌                                                                                                                        | 2/39 [00:01<00:13,  2.75it/s, loss=10.1, v_num=da23, train_loss_step=9.760, train_acc_step=12.00]
  | Name                 | Type                       | Params
--------------------------------------------------------------------
0 | model                | VisualBertModel            | 110 M
1 | text_prediction_head | VisualBertLMPredictionHead | 24.1 M
2 | seq_relationship     | Linear                     | 1.5 K
3 | transform_img_ft     | Linear                     | 1.0 M
4 | transform_img_box    | Linear                     | 5.1 K
5 | transform_ln_ft      | LayerNorm                  | 2.0 K
6 | transform_ln_box     | LayerNorm                  | 2.0 K
--------------------------------------------------------------------
135 M     Trainable params
0         Non-trainable params
135 M     Total params
543.152   Total estimated model params size (MB)
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2211: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (19) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.




Epoch 0:  49%|█████████████████████████████████████████████████████████████▍                                                                | 19/39 [00:09<00:09,  2.02it/s, loss=8.64, v_num=da23, train_loss_step=8.090, train_acc_step=20.60]
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 0:  64%|████████████████████████████████████████████████████████████████████████████████▊                                             | 25/39 [00:11<00:05,  2.35it/s, loss=8.64, v_num=da23, train_loss_step=8.090, train_acc_step=20.60]


Validating:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 15/20 [00:03<00:01,  4.42it/s]




Epoch 1:  51%|▌| 20/39 [00:09<00:08,  2.13it/s, loss=7.72, v_num=da23, train_loss_step=7.710, train_acc_step=21.90, val_loss_step=8.130, val_acc_step=19.20, val_loss_epoch=7.830, val_acc_epoch=20.70, train_loss_epoch=8.660, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 1:  67%|▋| 26/39 [00:11<00:05,  2.41it/s, loss=7.72, v_num=da23, train_loss_step=7.710, train_acc_step=21.90, val_loss_step=8.130, val_acc_step=19.20, val_loss_epoch=7.830, val_acc_epoch=20.70, train_loss_epoch=8.660, train_acc_epoch=


Validating:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 15/20 [00:03<00:01,  4.08it/s]




Epoch 2:  51%|▌| 20/39 [00:09<00:08,  2.17it/s, loss=7.35, v_num=da23, train_loss_step=6.960, train_acc_step=29.10, val_loss_step=7.740, val_acc_step=21.00, val_loss_epoch=7.370, val_acc_epoch=24.90, train_loss_epoch=7.690, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 2:  62%|▌| 24/39 [00:10<00:06,  2.37it/s, loss=7.35, v_num=da23, train_loss_step=6.960, train_acc_step=29.10, val_loss_step=7.740, val_acc_step=21.00, val_loss_epoch=7.370, val_acc_epoch=24.90, train_loss_epoch=7.690, train_acc_epoch=


Validating:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 13/20 [00:02<00:01,  4.28it/s]




Epoch 3:  51%|▌| 20/39 [00:10<00:09,  2.10it/s, loss=7.01, v_num=da23, train_loss_step=6.740, train_acc_step=29.80, val_loss_step=7.150, val_acc_step=27.20, val_loss_epoch=7.080, val_acc_epoch=26.50, train_loss_epoch=7.320, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 3:  56%|▌| 22/39 [00:10<00:07,  2.20it/s, loss=7.01, v_num=da23, train_loss_step=6.740, train_acc_step=29.80, val_loss_step=7.150, val_acc_step=27.20, val_loss_epoch=7.080, val_acc_epoch=26.50, train_loss_epoch=7.320, train_acc_epoch=


Validating:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 12/20 [00:02<00:01,  4.54it/s]




Epoch 4:  51%|▌| 20/39 [00:09<00:08,  2.12it/s, loss=6.94, v_num=da23, train_loss_step=7.040, train_acc_step=24.20, val_loss_step=7.380, val_acc_step=23.30, val_loss_epoch=6.940, val_acc_epoch=26.90, train_loss_epoch=7.030, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 4:  56%|▌| 22/39 [00:10<00:07,  2.22it/s, loss=6.94, v_num=da23, train_loss_step=7.040, train_acc_step=24.20, val_loss_step=7.380, val_acc_step=23.30, val_loss_epoch=6.940, val_acc_epoch=26.90, train_loss_epoch=7.030, train_acc_epoch=


Validating:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 12/20 [00:02<00:01,  4.59it/s]




Epoch 5:  51%|▌| 20/39 [00:10<00:09,  2.10it/s, loss=6.84, v_num=da23, train_loss_step=6.910, train_acc_step=28.60, val_loss_step=6.670, val_acc_step=28.90, val_loss_epoch=6.850, val_acc_epoch=27.40, train_loss_epoch=6.950, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 5:  56%|▌| 22/39 [00:10<00:07,  2.20it/s, loss=6.84, v_num=da23, train_loss_step=6.910, train_acc_step=28.60, val_loss_step=6.670, val_acc_step=28.90, val_loss_epoch=6.850, val_acc_epoch=27.40, train_loss_epoch=6.950, train_acc_epoch=


Validating:  55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 11/20 [00:02<00:02,  4.21it/s]




Epoch 6:  51%|▌| 20/39 [00:10<00:09,  2.06it/s, loss=6.71, v_num=da23, train_loss_step=6.350, train_acc_step=35.30, val_loss_step=6.710, val_acc_step=31.60, val_loss_epoch=6.770, val_acc_epoch=30.30, train_loss_epoch=6.820, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 6:  72%|▋| 28/39 [00:12<00:04,  2.38it/s, loss=6.71, v_num=da23, train_loss_step=6.350, train_acc_step=35.30, val_loss_step=6.710, val_acc_step=31.60, val_loss_epoch=6.770, val_acc_epoch=30.30, train_loss_epoch=6.820, train_acc_epoch=


Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 17/20 [00:04<00:00,  4.35it/s]




Epoch 7:  51%|▌| 20/39 [00:09<00:09,  2.10it/s, loss=6.61, v_num=da23, train_loss_step=6.430, train_acc_step=34.00, val_loss_step=6.900, val_acc_step=29.50, val_loss_epoch=6.610, val_acc_epoch=32.50, train_loss_epoch=6.710, train_acc_epoch=
Validating:   0%|                                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]
Epoch 7:  62%|▌| 24/39 [00:10<00:06,  2.29it/s, loss=6.61, v_num=da23, train_loss_step=6.430, train_acc_step=34.00, val_loss_step=6.900, val_acc_step=29.50, val_loss_epoch=6.610, val_acc_epoch=32.50, train_loss_epoch=6.710, train_acc_epoch=


Validating:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 13/20 [00:02<00:01,  4.35it/s]

Epoch 8:  13%|▏| 5/39 [00:02<00:15,  2.26it/s, loss=6.58, v_num=da23, train_loss_step=6.650, train_acc_step=32.60, val_loss_step=6.750, val_acc_step=29.90, val_loss_epoch=6.400, val_acc_epoch=34.20, train_loss_epoch=6.620, train_acc_epoch=3
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...

Epoch 8:  18%|▏| 7/39 [00:03<00:15,  2.12it/s, loss=6.57, v_num=da23, train_loss_step=6.310, train_acc_step=36.70, val_loss_step=6.750, val_acc_step=29.90, val_loss_epoch=6.400, val_acc_epoch=34.20, train_loss_epoch=6.620, train_acc_epoch=3