/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory /media/matt/data21/mmRad/checkpoints/ exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Global seed set to 808
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
Beginning training run with #1024 from mscoco_train for #100 epochs...
Start to load Faster-RCNN detected objects from /media/matt/data21/mmRad/img_features/mscoco-train_2017-custom.tsv
Loaded 1024 images in file /media/matt/data21/mmRad/img_features/mscoco-train_2017-custom.tsv in 1 seconds.
Start to load Faster-RCNN detected objects from /media/matt/data21/mmRad/img_features/mscoco-val_2017-custom.tsv
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded 5000 images in file /media/matt/data21/mmRad/img_features/mscoco-val_2017-custom.tsv in 7 seconds.
Validation sanity check: 0it [00:00, ?it/s]
  | Name                 | Type                       | Params
--------------------------------------------------------------------
0 | model                | VisualBertModel            | 111 M
1 | text_prediction_head | VisualBertLMPredictionHead | 24.1 M
2 | seq_relationship     | Linear                     | 1.5 K
3 | transform_img_ft     | Linear                     | 2.1 M
4 | transform_img_box    | Linear                     | 10.2 K
5 | transform_ln_ft      | LayerNorm                  | 4.1 K
6 | transform_ln_box     | LayerNorm                  | 4.1 K
--------------------------------------------------------------------
137 M     Trainable params
0         Non-trainable params
137 M     Total params

Validation sanity check:   0%|                                                                                                                                                        | 0/1 [00:00<?, ?it/s]
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:369: UserWarning: You requested to overfit but enabled val/test dataloader shuffling. We are turning it off for you.
  rank_zero_warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Epoch 0:   0%|                                                                                                                                                              | 0/2 [00:00<00:00, 1392.99it/s]
Global seed set to 808
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:255: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning off the training dataloader shuffling for you.
  rank_zero_warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/matt/anaconda3/envs/lxmert/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=2). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:  50%|██████████████████████████████████████████████                                              | 1/2 [00:02<00:01,  1.07s/it, loss=10.5, v_num=hypg, train_loss_step=10.50, train_acc_step=0.000]


Epoch 1:  50%|▌| 1/2 [00:22<00:11, 11.50s/it, loss=10, v_num=hypg, train_loss_step=9.480, train_acc_step=14.10, val_loss_step=9.340, val_acc_step=15.90, val_loss_epoch=9.340, val_acc_epoch=15.90, train_lo

Epoch 2: 100%|█| 2/2 [00:06<00:00,  2.02s/it, loss=10.1, v_num=hypg, train_loss_step=10.20, train_acc_step=1.860, val_loss_step=10.30, val_acc_step=0.000, val_loss_epoch=10.30, val_acc_epoch=0.000, train_


Epoch 3: 100%|█| 2/2 [00:06<00:00,  2.28s/it, loss=9.85, v_num=hypg, train_loss_step=9.230, train_acc_step=15.50, val_loss_step=9.220, val_acc_step=15.10, val_loss_epoch=9.220, val_acc_epoch=15.10, train_


Epoch 4: 100%|█| 2/2 [00:15<00:00,  5.32s/it, loss=9.65, v_num=hypg, train_loss_step=8.810, train_acc_step=16.30, val_loss_step=9.020, val_acc_step=13.30, val_loss_epoch=9.020, val_acc_epoch=13.30, train_


Epoch 5: 100%|█| 2/2 [01:33<00:00, 31.18s/it, loss=9.51, v_num=hypg, train_loss_step=8.810, train_acc_step=13.60, val_loss_step=8.780, val_acc_step=14.40, val_loss_epoch=8.780, val_acc_epoch=14.40, train_


